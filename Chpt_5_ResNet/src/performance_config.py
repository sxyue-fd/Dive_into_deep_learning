"""
æ€§èƒ½è°ƒä¼˜é…ç½®è§£æå™¨
ç”¨äºè§£æå’Œåº”ç”¨æ€§èƒ½é¢„è®¾é…ç½®
"""

import yaml
import copy
from typing import Dict, Any, List
from pathlib import Path


def load_performance_config(config_path: str = "configs/config_performance.yaml") -> Dict[str, Any]:
    """
    åŠ è½½å¹¶è§£ææ€§èƒ½è°ƒä¼˜é…ç½®æ–‡ä»¶
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        è§£æåçš„å®Œæ•´é…ç½®å­—å…¸
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # è·å–é€‰æ‹©çš„é¢„è®¾
    preset_name = config.get('performance_preset', 'baseline')
    
    if preset_name not in config['performance_presets']:
        raise ValueError(f"æœªæ‰¾åˆ°é¢„è®¾é…ç½®: {preset_name}")
    
    # åº”ç”¨é¢„è®¾é…ç½®
    preset = config['performance_presets'][preset_name]
    final_config = apply_performance_preset(config, preset)
    
    # åº”ç”¨æ‰‹åŠ¨è¦†ç›–
    manual_overrides = config.get('manual_overrides', {})
    if manual_overrides:
        final_config = apply_manual_overrides(final_config, manual_overrides)
    
    # åº”ç”¨é«˜çº§å‚æ•°
    final_config = apply_advanced_settings(final_config, config['advanced_performance'])
    
    print(f"âœ… å·²åŠ è½½æ€§èƒ½é¢„è®¾: {preset_name}")
    print(f"ğŸ“ é¢„è®¾æè¿°: {preset['description']}")
    print(f"ğŸ¯ å…³é”®å‚æ•°: epochs={final_config['training']['epochs']}, "
          f"batch_size={final_config['data']['batch_size']}, "
          f"lr={final_config['training']['learning_rate']}")
    
    return final_config


def apply_performance_preset(base_config: Dict[str, Any], preset: Dict[str, Any]) -> Dict[str, Any]:
    """åº”ç”¨æ€§èƒ½é¢„è®¾åˆ°åŸºç¡€é…ç½®"""
    config = copy.deepcopy(base_config)
    
    # ç¡®ä¿å¿…è¦çš„é…ç½®ç»“æ„å­˜åœ¨
    ensure_nested_dict(config, ['training'])
    ensure_nested_dict(config, ['data'])
    ensure_nested_dict(config, ['device'])
    ensure_nested_dict(config, ['logging'])
    ensure_nested_dict(config, ['checkpoint'])
    ensure_nested_dict(config, ['training_monitoring', 'early_stopping'])
    
    # æ˜ å°„é¢„è®¾å‚æ•°åˆ°é…ç½®ç»“æ„
    mapping = {
        'epochs': ['training', 'epochs'],
        'batch_size': ['data', 'batch_size'],
        'learning_rate': ['training', 'learning_rate'],
        'weight_decay': ['training', 'weight_decay'],
        'target_accuracy': ['training', 'target_accuracy'],
        'early_stopping_patience': ['training_monitoring', 'early_stopping', 'patience'],
        'scheduler': ['training', 'scheduler'],
        'optimizer': ['training', 'optimizer'],
        'mixed_precision': ['device', 'mixed_precision'],
        'num_workers': ['data', 'num_workers'],
        'log_frequency': ['logging', 'log_frequency'],
        'save_frequency': ['checkpoint', 'save_frequency']
    }
    
    # åº”ç”¨é¢„è®¾å‚æ•°
    for preset_key, config_path in mapping.items():
        if preset_key in preset:
            set_nested_value(config, config_path, preset[preset_key])
    
    return config


def apply_manual_overrides(config: Dict[str, Any], overrides: Dict[str, Any]) -> Dict[str, Any]:
    """åº”ç”¨æ‰‹åŠ¨è¦†ç›–å‚æ•°"""
    if not overrides:
        return config
    
    mapping = {
        'epochs': ['training', 'epochs'],
        'learning_rate': ['training', 'learning_rate'],
        'batch_size': ['data', 'batch_size'],
        'optimizer': ['training', 'optimizer'],
        'scheduler': ['training', 'scheduler'],
        'weight_decay': ['training', 'weight_decay'],
        'target_accuracy': ['training', 'target_accuracy']
    }
    
    overridden_params = []
    for override_key, value in overrides.items():
        if override_key in mapping:
            set_nested_value(config, mapping[override_key], value)
            overridden_params.append(f"{override_key}={value}")
    
    if overridden_params:
        print(f"ğŸ”§ æ‰‹åŠ¨è¦†ç›–å‚æ•°: {', '.join(overridden_params)}")
    
    return config


def apply_advanced_settings(config: Dict[str, Any], advanced: Dict[str, Any]) -> Dict[str, Any]:
    """åº”ç”¨é«˜çº§æ€§èƒ½è®¾ç½®"""
    
    # åº”ç”¨æ•°æ®å¢å¼ºè®¾ç½®
    aug_strength = advanced.get('augmentation_strength', 'medium')
    aug_config = advanced['augmentation_configs'].get(aug_strength, {})
    
    if 'random_horizontal_flip' in aug_config:
        set_nested_value(config, ['data', 'transforms', 'train', 'random_horizontal_flip'], 
                        aug_config['random_horizontal_flip'])
    if 'random_crop_padding' in aug_config:
        set_nested_value(config, ['data', 'transforms', 'train', 'random_crop', 'padding'], 
                        aug_config['random_crop_padding'])
    
    # åº”ç”¨ä¼˜åŒ–å™¨é…ç½®
    optimizer = config.get('training', {}).get('optimizer', 'adam')
    opt_config = advanced['optimizer_configs'].get(optimizer, {})
    if opt_config:
        ensure_nested_dict(config, ['training', 'optimizer_params'])
        config['training']['optimizer_params'].update(opt_config)
    
    # åº”ç”¨è°ƒåº¦å™¨é…ç½®
    scheduler = config.get('training', {}).get('scheduler', 'cosine')
    sched_config = advanced['scheduler_configs'].get(scheduler, {})
    if sched_config:
        ensure_nested_dict(config, ['training', 'scheduler_params'])
        config['training']['scheduler_params'].update(sched_config)
    
    return config


def set_nested_value(config: Dict[str, Any], path: list, value: Any):
    """è®¾ç½®åµŒå¥—å­—å…¸çš„å€¼"""
    current = config
    for key in path[:-1]:
        if key not in current:
            current[key] = {}
        current = current[key]
    current[path[-1]] = value


def ensure_nested_dict(config: Dict[str, Any], path: list):
    """ç¡®ä¿åµŒå¥—å­—å…¸è·¯å¾„å­˜åœ¨"""
    current = config
    for key in path:
        if key not in current:
            current[key] = {}
        current = current[key]


def print_performance_summary(config: Dict[str, Any]):
    """æ‰“å°æ€§èƒ½é…ç½®æ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸš€ æ€§èƒ½è°ƒä¼˜é…ç½®æ‘˜è¦")
    print("="*60)
    
    training = config.get('training', {})
    data = config.get('data', {})
    device = config.get('device', {})
    
    print(f"ğŸ“Š è®­ç»ƒå‚æ•°:")
    print(f"   - è®­ç»ƒè½®æ•°: {training.get('epochs', 'N/A')}")
    print(f"   - æ‰¹æ¬¡å¤§å°: {data.get('batch_size', 'N/A')}")
    print(f"   - å­¦ä¹ ç‡: {training.get('learning_rate', 'N/A')}")
    print(f"   - æƒé‡è¡°å‡: {training.get('weight_decay', 'N/A')}")
    print(f"   - ç›®æ ‡å‡†ç¡®ç‡: {training.get('target_accuracy', 'N/A')}")
    
    print(f"\nğŸ”§ ä¼˜åŒ–è®¾ç½®:")
    print(f"   - ä¼˜åŒ–å™¨: {training.get('optimizer', 'N/A')}")
    print(f"   - è°ƒåº¦å™¨: {training.get('scheduler', 'N/A')}")
    print(f"   - æ··åˆç²¾åº¦: {device.get('mixed_precision', 'N/A')}")
    print(f"   - æ•°æ®çº¿ç¨‹æ•°: {data.get('num_workers', 'N/A')}")
    
    print("="*60)


def get_config_value(config: Dict[str, Any], path: List[str], default=None):
    """å®‰å…¨åœ°è·å–é…ç½®å€¼ï¼Œæ”¯æŒåµŒå¥—è·¯å¾„
    
    Args:
        config: é…ç½®å­—å…¸
        path: é…ç½®è·¯å¾„åˆ—è¡¨ï¼Œå¦‚ ['training', 'learning_rate']
        default: é»˜è®¤å€¼
        
    Returns:
        é…ç½®å€¼æˆ–é»˜è®¤å€¼
    """
    current = config
    try:
        for key in path:
            current = current[key]
        return current
    except (KeyError, TypeError):
        return default


def get_early_stopping_config(config: Dict[str, Any]) -> Dict[str, Any]:
    """è·å–æ—©åœé…ç½®ï¼Œå…¼å®¹æ–°æ—§æ ¼å¼
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        æ—©åœé…ç½®å­—å…¸
    """
    # å°è¯•æ–°æ ¼å¼
    early_stopping_config = get_config_value(config, ['training_monitoring', 'early_stopping'], {})
    
    # å¦‚æœæ–°æ ¼å¼ä¸ºç©ºï¼Œå°è¯•æ—§æ ¼å¼
    if not early_stopping_config:
        early_stopping_config = get_config_value(config, ['training', 'early_stopping'], {})
    
    # è®¾ç½®é»˜è®¤å€¼
    return {
        'patience': early_stopping_config.get('patience', 10),
        'min_delta': early_stopping_config.get('min_delta', 0.001),
        'mode': early_stopping_config.get('mode', 'min')
    }


def get_random_seed(config: Dict[str, Any]) -> int:
    """è·å–éšæœºç§å­ï¼Œå…¼å®¹æ–°æ—§æ ¼å¼
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        éšæœºç§å­å€¼
    """
    # å°è¯•ä»æ ¹çº§åˆ«è·å–
    seed = get_config_value(config, ['random_seed'])
    if seed is not None:
        return seed
    
    # å°è¯•ä»dataé…ç½®è·å–
    seed = get_config_value(config, ['data', 'random_seed'])
    if seed is not None:
        return seed
    
    # é»˜è®¤å€¼
    return 42


if __name__ == "__main__":
    # æµ‹è¯•é…ç½®è§£æå™¨
    try:
        config = load_performance_config()
        print_performance_summary(config)
    except Exception as e:
        print(f"âŒ é…ç½®è§£æå¤±è´¥: {e}")
